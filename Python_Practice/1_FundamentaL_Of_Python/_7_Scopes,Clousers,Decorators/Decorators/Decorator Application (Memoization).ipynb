{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decorators Application (Memoization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go back to our Fibonacci example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fib(n):\n",
    "    print ('Calculating fib({0})'.format(n))\n",
    "    return 1 if n < 3 else fib(n-1) + fib(n-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run this, we see that it is quite inefficient, as the same Fibonacci numbers get calculated multiple times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fib(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be better if we could somehow \"store\" these results, so if we have calculated `fib(4)` and `fib(3)` before, we could simply recall the these values when calculating `fib(5) = fib(4) + fib(3)` instead of recalculating them.\n",
    "\n",
    "This concept of improving the efficiency of our code by caching pre-calculated values so they do not need to be re-calcualted every time, is called \"memoization\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can approach this using a simple class and a dictionary that stores any Fibonacci number that's already been calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Fib:\n",
    "    def __init__(self):\n",
    "        self.cache = {1: 1, 2: 1}\n",
    "    \n",
    "    def fib(self, n):\n",
    "        if n not in self.cache:\n",
    "            print('Calculating fib({0})'.format(n))\n",
    "            self.cache[n] = self.fib(n-1) + self.fib(n-2)\n",
    "        return self.cache[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = Fib()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.fib(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.fib(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f.fib(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how we could rewrite this using a closure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fib():\n",
    "    cache = {1: 1, 2: 2}\n",
    "    \n",
    "    def calc_fib(n):\n",
    "        if n not in cache:\n",
    "            print('Calculating fib({0})'.format(n))\n",
    "            cache[n] = calc_fib(n-1) + calc_fib(n-2)\n",
    "        return cache[n]\n",
    "    \n",
    "    return calc_fib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = fib()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(10)"
   ]
  },
  {
   "source": [
    "Now let's see how we would implement this using a decorator:"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "\n",
    "def memoize_fib(fn):\n",
    "    cache = dict()\n",
    "    \n",
    "    @wraps(fn)\n",
    "    def inner(n):\n",
    "        if n not in cache:\n",
    "            cache[n] = fn(n)\n",
    "        return cache[n]\n",
    "    \n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@memoize_fib\n",
    "def fib(n):\n",
    "    print ('Calculating fib({0})'.format(n))\n",
    "    return 1 if n < 3 else fib(n-1) + fib(n-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fib(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fib(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fib(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we are hitting the cache when the values are available.\n",
    "\n",
    "Now, we made our memoization decorator \"hardcoded\" to single argument functions - we could make it more generic.\n",
    "\n",
    "For example, to handle an arbitrary number of positional arguments and keyword-only arguments we could do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def memoize(fn):\n",
    "    cache = dict()\n",
    "    \n",
    "    @wraps(fn)\n",
    "    def inner(*args):\n",
    "        if args not in cache:\n",
    "            cache[args] = fn(*args)\n",
    "        return cache[args]\n",
    "    \n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@memoize\n",
    "def fib(n):\n",
    "    print ('Calculating fib({0})'.format(n))\n",
    "    return 1 if n < 3 else fib(n-1) + fib(n-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fib(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fib(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, with this rather generic memoization decorator we can memoize other functions too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fact(n):\n",
    "    print('Calculating {0}!'.format(n))\n",
    "    return 1 if n < 2 else n * fact(n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And memoizing it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@memoize\n",
    "def fact(n):\n",
    "    print('Calculating {0}!'.format(n))\n",
    "    return 1 if n < 2 else n * fact(n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our simple memoizer has a drawback however:\n",
    "* the cache size is unbounded - probably not a good thing! In general we want to limit the cache to a certain number of entries, balancing computational efficiency vs memory utilization.\n",
    "* we are not handling **kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memoization is such a common thing to do that Python actually has a memoization decorator built for us!\n",
    "\n",
    "It's in the, you guessed it, **functools** module, and is called **lru_cache** and is going to be quite a bit more efficient compared to the rudimentary memoization example we did above.\n",
    "\n",
    "[LRU Cache = Least Recently Used caching: since the cache is not unlimited, at some point cached entries need to be discarded, and the least recently used entries are discarded first]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@lru_cache()\n",
    "def fact(n):\n",
    "    print(\"Calculating fact({0})\".format(n))\n",
    "    return 1 if n < 2 else n * fact(n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Calculating fact(245)\nCalculating fact(244)\nCalculating fact(243)\nCalculating fact(242)\nCalculating fact(241)\nCalculating fact(240)\nCalculating fact(239)\nCalculating fact(238)\nCalculating fact(237)\nCalculating fact(236)\nCalculating fact(235)\nCalculating fact(234)\nCalculating fact(233)\nCalculating fact(232)\nCalculating fact(231)\nCalculating fact(230)\nCalculating fact(229)\nCalculating fact(228)\nCalculating fact(227)\nCalculating fact(226)\nCalculating fact(225)\nCalculating fact(224)\nCalculating fact(223)\nCalculating fact(222)\nCalculating fact(221)\nCalculating fact(220)\nCalculating fact(219)\nCalculating fact(218)\nCalculating fact(217)\nCalculating fact(216)\nCalculating fact(215)\nCalculating fact(214)\nCalculating fact(213)\nCalculating fact(212)\nCalculating fact(211)\nCalculating fact(210)\nCalculating fact(209)\nCalculating fact(208)\nCalculating fact(207)\nCalculating fact(206)\nCalculating fact(205)\nCalculating fact(204)\nCalculating fact(203)\nCalculating fact(202)\nCalculating fact(201)\nCalculating fact(200)\nCalculating fact(199)\nCalculating fact(198)\nCalculating fact(197)\nCalculating fact(196)\nCalculating fact(195)\nCalculating fact(194)\nCalculating fact(193)\nCalculating fact(192)\nCalculating fact(191)\nCalculating fact(190)\nCalculating fact(189)\nCalculating fact(188)\nCalculating fact(187)\nCalculating fact(186)\nCalculating fact(185)\nCalculating fact(184)\nCalculating fact(183)\nCalculating fact(182)\nCalculating fact(181)\nCalculating fact(180)\nCalculating fact(179)\nCalculating fact(178)\nCalculating fact(177)\nCalculating fact(176)\nCalculating fact(175)\nCalculating fact(174)\nCalculating fact(173)\nCalculating fact(172)\nCalculating fact(171)\nCalculating fact(170)\nCalculating fact(169)\nCalculating fact(168)\nCalculating fact(167)\nCalculating fact(166)\nCalculating fact(165)\nCalculating fact(164)\nCalculating fact(163)\nCalculating fact(162)\nCalculating fact(161)\nCalculating fact(160)\nCalculating fact(159)\nCalculating fact(158)\nCalculating fact(157)\nCalculating fact(156)\nCalculating fact(155)\nCalculating fact(154)\nCalculating fact(153)\nCalculating fact(152)\nCalculating fact(151)\nCalculating fact(150)\nCalculating fact(149)\nCalculating fact(148)\nCalculating fact(147)\nCalculating fact(146)\nCalculating fact(145)\nCalculating fact(144)\nCalculating fact(143)\nCalculating fact(142)\nCalculating fact(141)\nCalculating fact(140)\nCalculating fact(139)\nCalculating fact(138)\nCalculating fact(137)\nCalculating fact(136)\nCalculating fact(135)\nCalculating fact(134)\nCalculating fact(133)\nCalculating fact(132)\nCalculating fact(131)\nCalculating fact(130)\nCalculating fact(129)\nCalculating fact(128)\nCalculating fact(127)\nCalculating fact(126)\nCalculating fact(125)\nCalculating fact(124)\nCalculating fact(123)\nCalculating fact(122)\nCalculating fact(121)\nCalculating fact(120)\nCalculating fact(119)\nCalculating fact(118)\nCalculating fact(117)\nCalculating fact(116)\nCalculating fact(115)\nCalculating fact(114)\nCalculating fact(113)\nCalculating fact(112)\nCalculating fact(111)\nCalculating fact(110)\nCalculating fact(109)\nCalculating fact(108)\nCalculating fact(107)\nCalculating fact(106)\nCalculating fact(105)\nCalculating fact(104)\nCalculating fact(103)\nCalculating fact(102)\nCalculating fact(101)\nCalculating fact(100)\nCalculating fact(99)\nCalculating fact(98)\nCalculating fact(97)\nCalculating fact(96)\nCalculating fact(95)\nCalculating fact(94)\nCalculating fact(93)\nCalculating fact(92)\nCalculating fact(91)\nCalculating fact(90)\nCalculating fact(89)\nCalculating fact(88)\nCalculating fact(87)\nCalculating fact(86)\nCalculating fact(85)\nCalculating fact(84)\nCalculating fact(83)\nCalculating fact(82)\nCalculating fact(81)\nCalculating fact(80)\nCalculating fact(79)\nCalculating fact(78)\nCalculating fact(77)\nCalculating fact(76)\nCalculating fact(75)\nCalculating fact(74)\nCalculating fact(73)\nCalculating fact(72)\nCalculating fact(71)\nCalculating fact(70)\nCalculating fact(69)\nCalculating fact(68)\nCalculating fact(67)\nCalculating fact(66)\nCalculating fact(65)\nCalculating fact(64)\nCalculating fact(63)\nCalculating fact(62)\nCalculating fact(61)\nCalculating fact(60)\nCalculating fact(59)\nCalculating fact(58)\nCalculating fact(57)\nCalculating fact(56)\nCalculating fact(55)\nCalculating fact(54)\nCalculating fact(53)\nCalculating fact(52)\nCalculating fact(51)\nCalculating fact(50)\nCalculating fact(49)\nCalculating fact(48)\nCalculating fact(47)\nCalculating fact(46)\nCalculating fact(45)\nCalculating fact(44)\nCalculating fact(43)\nCalculating fact(42)\nCalculating fact(41)\nCalculating fact(40)\nCalculating fact(39)\nCalculating fact(38)\nCalculating fact(37)\nCalculating fact(36)\nCalculating fact(35)\nCalculating fact(34)\nCalculating fact(33)\nCalculating fact(32)\nCalculating fact(31)\nCalculating fact(30)\nCalculating fact(29)\nCalculating fact(28)\nCalculating fact(27)\nCalculating fact(26)\nCalculating fact(25)\nCalculating fact(24)\nCalculating fact(23)\nCalculating fact(22)\nCalculating fact(21)\nCalculating fact(20)\nCalculating fact(19)\nCalculating fact(18)\nCalculating fact(17)\nCalculating fact(16)\nCalculating fact(15)\nCalculating fact(14)\nCalculating fact(13)\nCalculating fact(12)\nCalculating fact(11)\nCalculating fact(10)\nCalculating fact(9)\nCalculating fact(8)\nCalculating fact(7)\nCalculating fact(6)\nCalculating fact(5)\nCalculating fact(4)\nCalculating fact(3)\nCalculating fact(2)\nCalculating fact(1)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3446381088548184667326770790875951922006976951375582384611003611981639529782351868763804143237672379379846868628577527599609043944010849343355183826916579274876093562728501050027821075609832035303654996749361753195163012769070700485723141551669720900953728011558584003035375928212655846940281367061125645619508966404523085638743763256980870494465156859819224514274661087972929242817912092409671474491631797677547338910924800000000000000000000000000000000000000000000000000000000000"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "fact(245)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "fact(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, `fact(4)` was returned via a cached entry!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same thing with our Fibonacci function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache()\n",
    "def fib(n):\n",
    "    print(\"Calculating fib({0})\".format(n))\n",
    "    return 1 if n < 3 else fib(n-1) + fib(n-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fib(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fib(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall from a few videos back that we timed the calculation for Fibonacci numbers. Calculating fib(35) took several seconds - every time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fib_no_memo(n):\n",
    "    return 1 if n < 3 else fib_no_memo(n-1) + fib_no_memo(n-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = perf_counter()\n",
    "result = fib_no_memo(35)\n",
    "print(\"result={0}, elapsed: {1}s\".format(result, perf_counter() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@lru_cache()\n",
    "def fib_memo(n):\n",
    "    return 1 if n < 3 else fib_memo(n-1) + fib_memo(n-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = perf_counter()\n",
    "result = fib_memo(35)\n",
    "print(\"result={0}, elapsed: {1}s\".format(result, perf_counter() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we make the calls again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = perf_counter()\n",
    "result = fib_no_memo(35)\n",
    "print(\"result={0}, elapsed: {1}s\".format(result, perf_counter() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = perf_counter()\n",
    "result = fib_memo(35)\n",
    "print(\"result={0}, elapsed: {1}s\".format(result, perf_counter() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that the `lru_cache` decorator was implemented using `()` - we'll see more on this later, but that's because decorators can themselves have parameters (beyond the function being decorated)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the arguments to the `lru_cache` decorator is the size of the cache - it defaults to 128 items, but we can easily change this - for performance reasons use powers of 2 for the cache size (or None for unbounded cache):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=8)\n",
    "def fib(n):\n",
    "    print(\"Calculating fib({0})\".format(n))\n",
    "    return 1 if n < 3 else fib(n-1) + fib(n-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Calculating fib(10)\nCalculating fib(9)\nCalculating fib(8)\nCalculating fib(7)\nCalculating fib(6)\nCalculating fib(5)\nCalculating fib(4)\nCalculating fib(3)\nCalculating fib(2)\nCalculating fib(1)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "fib(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Calculating fib(20)\nCalculating fib(19)\nCalculating fib(18)\nCalculating fib(17)\nCalculating fib(16)\nCalculating fib(15)\nCalculating fib(14)\nCalculating fib(13)\nCalculating fib(12)\nCalculating fib(11)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "6765"
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "fib(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Calculating fib(34)\nCalculating fib(33)\nCalculating fib(32)\nCalculating fib(31)\nCalculating fib(30)\nCalculating fib(29)\nCalculating fib(28)\nCalculating fib(27)\nCalculating fib(26)\nCalculating fib(25)\nCalculating fib(24)\nCalculating fib(23)\nCalculating fib(22)\nCalculating fib(21)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5702887"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "fib(34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll not how Python had to recalculate `fib` for `10, 9,` etc. This is because the cache can only contain 10 items, so when we calculated `fib(20)`, it stored fib for `20, 19, ..., 11` (10 items) and therefore the oldest items fib `10, 9, ..., 1` were removed from the cache to make space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}